# @package _global_

defaults:
  # benchmark (task + simulator + dataset) related defaults:
  - /benchmark/rearrange: multi_agent_tidy_house_fp_spot_humanoid
  - /habitat/simulator/sim_sensors@habitat_baselines.eval.extra_sim_sensors.third_rgb_sensor: third_rgb_sensor
  - /habitat/task/measurements:
    - composite_subgoal_reward
  - /habitat/task/lab_sensors:
    - relative_resting_pos_sensor
    - target_start_sensor
    - goal_sensor
    - joint_sensor
    - is_holding_sensor
    - end_effector_sensor
    - target_start_gps_compass_sensor
    - target_goal_gps_compass_sensor
    - localization_sensor
    - humanoid_joint_sensor
    - other_agent_gps
    - has_finished_oracle_nav
    - humanoid_detector_sensor
  # needed for the shortest path finder
  - /habitat/task/actions@habitat.task.actions.agent_0_oracle_nav_action: oracle_nav_action
  - /habitat/task/actions@habitat.task.actions.agent_1_oracle_nav_action: oracle_nav_action
  # add control action for robot motion
  - /habitat/task/actions@habitat.task.actions.agent_0_motion_control: base_velocity_leg_animation_motion

  # baselines (algorithms used to control the agents) related defaults:
  - /habitat_baselines: habitat_baselines_rl_config_base
  - /habitat_baselines/rl/agent: pop_play  # multi agent access manager
  # agent 0
  - /habitat_baselines/rl/policy/obs_transforms@habitat_baselines.rl.policy.agent_0.obs_transforms.add_virtual_keys:
    - add_virtual_keys_base
  - /habitat_baselines/rl/policy@habitat_baselines.rl.policy.agent_0: hab3_hl_neural_ma
  - /habitat_baselines/rl/policy/hierarchical_policy/defined_skills@habitat_baselines.rl.policy.agent_0.hierarchical_policy.defined_skills: oracle_skills_ma
  # agent 1
  - /habitat_baselines/rl/policy/obs_transforms@habitat_baselines.rl.policy.agent_1.obs_transforms.add_virtual_keys:
    - add_virtual_keys_base
  - /habitat_baselines/rl/policy@habitat_baselines.rl.policy.agent_1: hab3_hl_neural_ma
  - /habitat_baselines/rl/policy/hierarchical_policy/defined_skills@habitat_baselines.rl.policy.agent_1.hierarchical_policy.defined_skills: oracle_skills_ma_humanoid

  # overrides
  - override /habitat/simulator/agents@habitat.simulator.agents.agent_0: rgbd_head_rgbdp_arm_agent
  - override /habitat/task/actions@habitat.task.actions.agent_0_base_velocity: base_velocity_leg_animation

  - _self_

habitat:
  task:
    lab_sensors:
      agent_0_should_replan:
        x_len: 2.0
        y_len: 1.5
        agent_idx: 0
      agent_1_should_replan:
        x_len: 2.0
        y_len: 1.5
        agent_idx: 1
    actions:
      agent_0_arm_action:
        grip_controller: MagicGraspAction
        type: "ArmAction"
        arm_controller: "ArmRelPosMaskKinematicAction"
        arm_joint_mask: [1,1,0,1,1,1,1]
        arm_joint_dimensionality: 7
        grasp_thresh_dist: 0.7
        disable_grip: False
        delta_pos_limit: 0.10 # default value 0.20
        ee_ctrl_lim: 0.015
      agent_0_base_velocity:
        allow_dyn_slide: True
        collision_threshold: 1e-5
        navmesh_offset: [[0.0, 0.0], [0.275, 0.0]]
        enable_lateral_move: False
        # This longitudinal_lin_speed and ang_speed are used for training skills
        longitudinal_lin_speed: 7.5 # default value 10.0
        lateral_lin_speed: 7.5 # default value 10.0
        ang_speed: 10.0
        enable_rotation_check_for_dyn_slide: False
      agent_0_motion_control:
        allow_dyn_slide: True
        collision_threshold: 1e-5
        navmesh_offset: [[0.0, 0.0], [0.275, 0.0]]
        enable_lateral_move: False
        # This longitudinal_lin_speed and ang_speed are used for training skills
        longitudinal_lin_speed: 10.0
        lateral_lin_speed: 10.0
        ang_speed: 10.0
        enable_rotation_check_for_dyn_slide: False
      agent_0_oracle_nav_action:
        type: OracleNavCoordAction
        allow_dyn_slide: True
        collision_threshold: 1e-5
        navmesh_offset: [[0.0, 0.0], [0.275, 0.0]]
        enable_lateral_move: False
        # This longitudinal_lin_speed and ang_speed are used for training skills
        longitudinal_lin_speed: 7.5 # default value 10.0
        lateral_lin_speed: 7.5 # default value 10.0
        ang_speed: 10.0
        enable_rotation_check_for_dyn_slide: False
      agent_1_oracle_nav_action:
        type: OracleNavAction
        motion_control: human_joints
        spawn_max_dist_to_obj: -1
    measurements:
      cooperate_subgoal_reward:
        end_on_collide: False
    constraint_violation_drops_object: False
  environment:
    max_episode_steps: 1000
    iterator_options:
      max_scene_repeat_steps: -1
      cycle: False
  gym:
    obs_keys:
      - agent_0_articulated_agent_arm_depth
      - agent_0_relative_resting_position
      - agent_0_obj_start_sensor
      - agent_0_obj_goal_sensor
      - agent_0_obj_start_gps_compass
      - agent_0_obj_goal_gps_compass
      - agent_0_joint
      - agent_0_is_holding
      - agent_0_ee_pos
      - agent_0_localization_sensor
      - agent_0_other_agent_gps
      - agent_0_humanoid_detector_sensor
  simulator:
    agents:
      agent_0:
        radius: 0.25
        height: 1.3
        articulated_agent_urdf: data/robots/hab_spot_arm/urdf/hab_spot_arm.urdf
        articulated_agent_type: "SpotRobot"
        sim_sensors:
          arm_rgb_sensor:
            height: 480
            width: 640
            hfov: 47
          arm_depth_sensor:
            height: 224
            width: 171
            hfov: 55
      agent_1:
        articulated_agent_urdf: 'data/humanoids/humanoid_data/male_1/male_1.urdf'
        articulated_agent_type: 'KinematicHumanoid'
        rest_pose_data_path: 'data/humanoids/humanoid_data/standing_pose_smplx.pkl'
        motion_data_path: "data/humanoids/humanoid_data/male_1/male_1_motion_data_smplx.pkl"
    kinematic_mode: True
    ac_freq_ratio: 1
    step_physics: True
    habitat_sim_v0:
      allow_sliding: True
  dataset:
    data_path: "data/datasets/floorplanner/rearrange/scratch/train/demo_25.json.gz"

habitat_baselines:
  num_environments: 1
  evaluate: True
  eval:
    should_load_ckpt: False
  rl:
    agent:
      num_pool_agents_per_type: [1, 8]
      agent_sample_interval: 20
    policy:
      agent_0:
        hierarchical_policy:
          high_level_policy:
            allowed_actions:
              - nav_to_receptacle_by_name
              - nav_to_goal
              - nav_to_obj
              - pick
              - place
            policy_input_keys:
              - "joint"
              - "is_holding"
              - "obj_start_sensor"
              - "obj_goal_sensor"
              - "obj_start_gps_compass"
              - "obj_goal_gps_compass"
              - "other_agent_gps"
          # Override to use the oracle navigation skill (which will actually execute navigation).
          defined_skills:
            pick:
              skill_name: "PickSkillPolicy"
              obs_skill_inputs: ["obj_start_sensor"]
              load_ckpt_file: "data/models/pick_latest.pth"
              max_skill_steps: 250
              obs_skill_input_dim: 3
            place:
              skill_name: "PlaceSkillPolicy"
              # We can swtich between if we want to use pick skill to replace place skill
              # or just use the true place skill
              # Use the place skill
              # obs_skill_inputs: ["obj_goal_sensor"]
              # load_ckpt_file: "data/models/place_ckpt.343.pth"
              # use_pick_skill_as_place_skill: False
              # Use the pick skill to be the place skill
              obs_skill_inputs: ["obj_start_sensor"]
              load_ckpt_file: "data/models/pick_latest.pth"
              use_pick_skill_as_place_skill: True
              max_skill_steps: 250
              obs_skill_input_dim: 3
            # Note that the pddl_action_names for nav_to_obj and nav_to_robot cannot contain
            # the action_names from each other. Otherwise, the planner will only call the
            # latest skill definition
            nav_to_obj:
              skill_name: "NavSkillPolicy"
              obs_skill_inputs: ["goal_to_agent_gps_compass"]
              load_ckpt_file: "data/models/point_nav_ckpt.2545.pth"
              max_skill_steps: 750
              obs_skill_input_dim: 2
              pddl_action_names: ["nav_to_obj", "nav_to_goal", "nav_to_receptacle_by_name"]
            # Load the social nav policy
            nav_to_robot:
              skill_name: "NavSkillPolicy"
              obs_skill_inputs: ["goal_to_agent_gps_compass"]
              load_ckpt_file: "data/models/social_nav_ckpt.1297.pth"
              obs_skill_input_dim: 2
              pddl_action_names: [ "nav_to_goal", "nav_to_robot", "nav_to_receptacle_by_name"]
      agent_1:
        hierarchical_policy:
          high_level_policy:
            allowed_actions:
              - nav_to_receptacle_by_name
              - nav_to_goal
              - nav_to_obj
              - pick
              - place
            policy_input_keys:
              - "head_depth"
              - "humanoid_joint_sensor"
              - "is_holding"
              - "obj_start_sensor"
              - "obj_goal_sensor"
              - "obj_start_gps_compass"
              - "obj_goal_gps_compass"
              - "other_agent_gps"
          # Override to use the oracle navigation skill (which will actually execute navigation).
          defined_skills:
            nav_to_obj:
              skill_name: "OracleNavPolicy"
              obs_skill_inputs: ["obj_start_sensor", "abs_obj_start_sensor", "obj_goal_sensor", "abs_obj_goal_sensor"]
              max_skill_steps: 300
              stop_thresh: 0.00001
              apply_postconds: False
    ddppo:
      # Whether to reset the critic linear layer
      reset_critic: False
      # Model parameters
      backbone: resnet18
      rnn_type: LSTM
      num_recurrent_layers: 2
