TENSORBOARD_DIR: "/checkpoint/eundersander/gala_kinematic/tb/gala_kinematic_ddppo"
CHECKPOINT_FOLDER: "/checkpoint/eundersander/gala_kinematic/ckpt/gala_kinematic_ddppo"
VIDEO_DIR: "../videos"
REWARD_SCALE: 1.0 # 0.01
NUM_CHECKPOINTS: 0
BATCHED_ENV: True
OVERLAP_PHYSICS: True
SAVE_VIDEOS_INTERVAL: 500
LOG_INTERVAL: 1
NUM_UPDATES: -1
TOTAL_NUM_STEPS: 20000000.0
NUM_ENVIRONMENTS: 512
SENSORS: ["DEPTH_SENSOR", "RGB_SENSOR", "ROBOT_START_RELATIVE", "ROBOT_TARGET_RELATIVE", "EE_START_RELATIVE", "EE_TARGET_RELATIVE", "ROBOT_EE_RELATIVE", "JOINT_SENSOR"]
SIMULATOR:
  AGENTS: ['AGENT_0']
  HEAD_RGB_SENSOR:
    WIDTH: 128
    HEIGHT: 128
  HEAD_DEPTH_SENSOR:
    WIDTH: 128
    HEIGHT: 128
    MIN_DEPTH: 0.0
    MAX_DEPTH: 10.0
    NORMALIZE_DEPTH: true

WRITER_TYPE: "wb"
WB:
  PROJECT_NAME: "gala"
  ENTITY: "vincentpierre"
  GROUP: ""
  RUN_NAME: ""
RL:
  PPO:
    ppo_epoch: 1
    num_steps: 32
    entropy_coef: 0.0 # 001
    lr: 2.5e-4
    use_normalized_advantage: True
    use_linear_lr_decay: False
    max_grad_norm: 100.0
  POLICY:
    name: "PointNavBaselinePolicy"
    action_distribution_type: "gaussian"
  DDPPO:
    backbone: "PointNavResNetPolicy"
FORCE_BLIND_POLICY: False
