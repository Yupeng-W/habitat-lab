# Copyright (c) Meta Platforms, Inc. All Rights Reserved

LOAD_CONFIG_FROM_CHECKPOINT: True
TENSORBOARD_DIR: "/checkpoint/eundersander/gala_kinematic/tb/gala_kinematic_ddppo"
CHECKPOINT_FOLDER: "/checkpoint/eundersander/gala_kinematic/ckpt/gala_kinematic_ddppo"
VIDEO_DIR: "../videos2"
VIDEO_OPTION: []
REWARD_SCALE: 1.0 # 0.01
NUM_CHECKPOINTS: 1000
BATCHED_ENV: True
OVERLAP_PHYSICS: True
SAVE_VIDEOS_INTERVAL: -1
LOG_INTERVAL: 10
LOG_INFO: True
LOG_INFO_NUM_ENVS: 10
NUM_UPDATES: -1
TOTAL_NUM_STEPS: 1.5e10
NUM_ENVIRONMENTS: 128
MAX_EPISODE_LENGTH: 500
NUM_EPISODES: 10000
MIN_NON_TARGET: 27
MAX_NON_TARGET: 32
FIXED_ROBOT_START_POSITION: False
PREVENT_STOP_ACTION: False
END_ACTION_THRESHOLD: 0.5
DROP_THRESHOLD: 0.5
GRASP_THRESHOLD: 0.5
STAGGER: True
ENABLE_SLIDING: False #True
TEST_EPISODE_COUNT: 10
EVALUATION_MODE: False
TRAIN_DATASET: None
EVAL_DATASET: None
BLIND: False
PROCEDURAL_GENERATION: False
ENABLE_ROBOT_COLLISION: True
ENABLE_HELD_OBJECT_COLLISION: True
DEBUG_SIM: False
CARTHESIAN_REWARD: 1.0
PICK_REWARD : 5.0
TASK_IS_PLACE : True
TASK_HAS_SIMPLE_PLACE: False
TASK_IS_NAV_PICK_NAV_REACH: False
TASK_IS_PICK_ONLY_FAIL_IF_BAD_ATTEMPT: False
TASK_IS_SIMPLE_PICK: False
TASK_NO_END_ACTION: False
LOCK_BASE: False
DO_NOT_END_IF_DROP_WRONG: False
DROP_WRONG_PENALTY: 0.0
ACTION_PENALTY_ON_BASE: False
ACTION_PENALTY_ON_DIFF: True
NPNP_SUCCESS_REWARD: 10.0
NPNP_SLACK_PENALTY: 0.0
ACTION_PENALTY: 0.0
NPNP_SUCCESS_THRESH: 0.1 #0.15 #0.3 #0.05
NPNP_FAILURE_PENALTY: 0.0
DROP_IS_FAIL: True
STATE_SENSORS:
  ROBOT_START_RELATIVE:
    TYPE: "RobotStartSensorConfig"
    polar: False
    obs_key: "robot_start_relative"
    shape: 3
  ROBOT_TARGET_RELATIVE:
    TYPE: "RobotTargetSensorConfig"
    polar: False
    obs_key: "robot_target_relative"
    shape: 3
  ROBOT_GOAL_RELATIVE:
    TYPE: "RobotGoalSensorConfig"
    polar: False
    obs_key: "robot_goal_relative"
    shape: 3
  EE_GOAL_RELATIVE:
    TYPE: "EEGoalSensorConfig"
    polar: False
    obs_key: "ee_goal_relative"
    shape: 3
  EE_START_RELATIVE:
    TYPE: "EEStartSensorConfig"
    polar: False
    obs_key: "ee_start_relative"
    shape: 3
  EE_TARGET_RELATIVE:
    TYPE: "EETargetSensorConfig"
    polar: False
    obs_key: "ee_target_relative"
    shape: 3
  ROBOT_EE_RELATIVE:
    TYPE: "RobotEESensorConfig"
    polar: False
    obs_key: "robot_ee_relative"
    shape: 3
  JOINT_SENSOR:
    TYPE: "JointSensorConfig"
    obs_key: "joint_pos"
    shape: 7
  STEP_COUNT_SENSOR:
    TYPE: "StepCountSensorConfig"
    obs_key: "step_count"
    shape: 3
  IS_HOLDING_SENSOR:
    TYPE: "HoldingSensorConfig"
    obs_key: "is_holding"
    shape: 1
SENSORS: ["DEPTH_SENSOR", "RGB_SENSOR", "ROBOT_TARGET_RELATIVE", "EE_TARGET_RELATIVE", "ROBOT_EE_RELATIVE", "ROBOT_GOAL_RELATIVE", "EE_GOAL_RELATIVE", "IS_HOLDING_SENSOR", "JOINT_SENSOR", "STEP_COUNT_SENSOR"]
SIMULATOR:
  AGENTS: ['AGENT_0']
  HEAD_RGB_SENSOR:
    WIDTH: 128
    HEIGHT: 128
  HEAD_DEPTH_SENSOR:
    WIDTH: 128
    HEIGHT: 128
    MIN_DEPTH: 0.0
    MAX_DEPTH: 10.0
    NORMALIZE_DEPTH: true

WRITER_TYPE: "wb"
WB:
  PROJECT_NAME: "gala"
  ENTITY: "galactic"
  GROUP: ""
  RUN_NAME: ""
RL:
  PPO:
    ppo_epoch: 1
    num_mini_batch: 2
    num_steps: 64
    entropy_coef: 0.001
    lr: 3.5e-4
    use_normalized_advantage: True
    use_linear_lr_decay: True
    max_grad_norm: 2.0
  POLICY:
    name: "PointNavResNetPolicy" # PointNavBaselinePolicy
    action_distribution_type: "gaussian_and_categorical"
  DDPPO:
    backbone: "resnet18"
FORCE_BLIND_POLICY: False
