TENSORBOARD_DIR: "/checkpoint/eundersander/gala_kinematic/tb/gala_kinematic_ddppo"
CHECKPOINT_FOLDER: "/checkpoint/eundersander/gala_kinematic/ckpt/gala_kinematic_ddppo"
VIDEO_DIR: "../videos2"
VIDEO_OPTION: ["disk"]
REWARD_SCALE: 1.0 # 0.01
NUM_CHECKPOINTS: 100
BATCHED_ENV: True
OVERLAP_PHYSICS: True
SAVE_VIDEOS_INTERVAL: -1
LOG_INTERVAL: 10
NUM_UPDATES: -1
TOTAL_NUM_STEPS: 5e9
NUM_ENVIRONMENTS: 128
MAX_EPISODE_LENGTH: 500
NUM_EPISODES: 10000
MIN_NON_TARGET: 27
MAX_NON_TARGET: 32
FIXED_ROBOT_START_POSITION: False
PREVENT_STOP_ACTION: False
STAGGER: True
TEST_EPISODE_COUNT: 10
EVALUATION_MODE: False
TRAIN_DATASET: ../data/train_generated.episode_set.json
EVAL_DATASET: ../data/test_generated.episode_set.json
BLIND: False
PROCEDURAL_GENERATION: False
ENABLE_ROBOT_COLLISION: True
ENABLE_HELD_OBJECT_COLLISION: True
DEBUG_SIM: False
PICK_REWARD : 5.0
TASK_IS_PLACE : True
TASK_IS_PICK_ONLY_FAIL_IF_BAD_ATTEMPT: False
NPNP_SUCCESS_REWARD: 10.0
NPNP_SLACK_PENALTY: 0.0
NPNP_SUCCESS_THRESH: 0.15 #0.3 #0.05
NPNP_FAILURE_PENALTY: 0.0
DROP_IS_FAIL: True
STATE_SENSORS:
  ROBOT_START_RELATIVE:
    TYPE: "RobotStartSensorConfig"
    polar: False
    obs_key: "robot_start_relative"
    shape: 3
  ROBOT_TARGET_RELATIVE:
    TYPE: "RobotTargetSensorConfig"
    polar: False
    obs_key: "robot_target_relative"
    shape: 3
  ROBOT_GOAL_RELATIVE:
    TYPE: "RobotGoalSensorConfig"
    polar: False
    obs_key: "robot_goal_relative"
    shape: 3
  EE_GOAL_RELATIVE:
    TYPE: "EEGoalSensorConfig"
    polar: False
    obs_key: "ee_goal_relative"
    shape: 3
  EE_START_RELATIVE:
    TYPE: "EEStartSensorConfig"
    polar: False
    obs_key: "ee_start_relative"
    shape: 3
  EE_TARGET_RELATIVE:
    TYPE: "EETargetSensorConfig"
    polar: False
    obs_key: "ee_target_relative"
    shape: 3
  ROBOT_EE_RELATIVE:
    TYPE: "RobotEESensorConfig"
    polar: False
    obs_key: "robot_ee_relative"
    shape: 3
  JOINT_SENSOR:
    TYPE: "JointSensorConfig"
    obs_key: "joint_pos"
    shape: 7
  STEP_COUNT_SENSOR:
    TYPE: "StepCountSensorConfig"
    obs_key: "step_count"
    shape: 3
  IS_HOLDING_SENSOR:
    TYPE: "HoldingSensorConfig"
    obs_key: "is_holding"
    shape: 1
SENSORS: ["DEPTH_SENSOR", "RGB_SENSOR", "ROBOT_TARGET_RELATIVE", "EE_TARGET_RELATIVE", "ROBOT_EE_RELATIVE", "ROBOT_GOAL_RELATIVE", "EE_GOAL_RELATIVE", "IS_HOLDING_SENSOR", "JOINT_SENSOR", "STEP_COUNT_SENSOR"]
SIMULATOR:
  AGENTS: ['AGENT_0']
  HEAD_RGB_SENSOR:
    WIDTH: 128
    HEIGHT: 128
  HEAD_DEPTH_SENSOR:
    WIDTH: 128
    HEIGHT: 128
    MIN_DEPTH: 0.0
    MAX_DEPTH: 10.0
    NORMALIZE_DEPTH: true

WRITER_TYPE: "wb"
WB:
  PROJECT_NAME: "gala"
  ENTITY: "vincentpierre"
  GROUP: ""
  RUN_NAME: ""
RL:
  PPO:
    ppo_epoch: 1
    num_mini_batch: 2
    num_steps: 64
    entropy_coef: 0.001
    lr: 3.5e-4
    use_normalized_advantage: True
    use_linear_lr_decay: True
    max_grad_norm: 2.0
  POLICY:
    name: "PointNavResNetPolicy"
    action_distribution_type: "gaussian_and_categorical"
  DDPPO:
    backbone: "resnet18"
FORCE_BLIND_POLICY: False
